services:
  rcnn:
    build:
      context: .
      dockerfile: Dockerfile.rcnn
    image: rcnn:latest
    container_name: rcnn_bdd
    volumes:
      - ./assignment_data_bdd:/app/assignment_data_bdd
      - ./mlruns:/app/mlruns # Share MLflow data with MLflow server
      - ./artifacts:/app/artifacts # Store artifacts
      - ./models/rcnn:/app/models/rcnn
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - PYTHONUNBUFFERED=1
    working_dir: /app
    tty: true
    stdin_open: true
    command: bash # ["uv", "run", "main.py", "--model", "RCNN"]
    networks:
      - bdd_network
    depends_on:
      - mlflow
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  yolo:
    build:
      context: .
      dockerfile: Dockerfile.yolo
    image: yolo:latest
    container_name: yolo_bdd_container
    volumes:
      - ./dataset_yolo:/app/dataset_yolo
      - ./bdd_yolov8:/app/bdd_yolov8
      - ./mlruns:/mlruns # Share MLflow data with MLflow server
      - ./artifacts:/app/artifacts # Store artifacts
    working_dir: /app
    tty: true
    stdin_open: true
    command: bash # python main.py --model YOLO --flavour yolov8n
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000 # Point to MLflow service
      - PYTHONUNBUFFERED=1
    networks:
      - bdd_network
    depends_on:
      - mlflow
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  yoloinf:
    build:
      context: .
      dockerfile: Dockerfile.yoloinf
    image: yolo_inf:latest
    container_name: yolo_inf_container
    working_dir: /app
    volumes:
      - ./assignment_data_bdd/bdd100k_images_100k/bdd100k/images/100k/test:/app/test
      - ./output_files:/app/output_files
      - ./models/yolo:/app/models/yolo
    tty: true
    stdin_open: true
    command: uv run inference_yolo.py
    networks:
      - bdd_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    image: mlflow:latest
    container_name: mlflow_server
    ports:
      - 5000:5000 # Expose MLflow UI on host port 5000
    volumes:
      - ./mlruns:/mlruns # Persist MLflow data
      - ./artifacts:/artifacts # Store artifacts
    networks:
      - bdd_network

networks:
  bdd_network:
    driver: bridge
